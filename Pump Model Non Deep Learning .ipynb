{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": true
            },
            "source": "<h1>Non Deep Learning Pump Model</h1>\n<p>This model uses a Support Vector Machine to classify the pump data in order to predict normal vs recovering/broken timestamps. The hidden code block following this markdown cell is where the data is read in from the object store and put into a DataFrame. The data in the DataFrame comes from the Feature Creation Deliverable Notebook. The second hidden cell is for the PCA data that comes from the second part of the Feature Creation Notebook. Both of the SVMs use GridSearchCV to tune the correct kernel and gamma settings. Predictions for both iterations are made using the best parameters from the grid search and the F1-score and Matthews Correlation Coefficient is calculated.</p>"
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>timestamp</th>\n      <th>sensor_00</th>\n      <th>sensor_01</th>\n      <th>sensor_02</th>\n      <th>sensor_03</th>\n      <th>sensor_04</th>\n      <th>sensor_05</th>\n      <th>sensor_06</th>\n      <th>sensor_07</th>\n      <th>sensor_08</th>\n      <th>sensor_09</th>\n      <th>sensor_10</th>\n      <th>sensor_11</th>\n      <th>sensor_12</th>\n      <th>sensor_13</th>\n      <th>sensor_14</th>\n      <th>sensor_16</th>\n      <th>sensor_17</th>\n      <th>sensor_18</th>\n      <th>sensor_19</th>\n      <th>sensor_20</th>\n      <th>sensor_21</th>\n      <th>sensor_22</th>\n      <th>sensor_23</th>\n      <th>sensor_24</th>\n      <th>sensor_25</th>\n      <th>sensor_26</th>\n      <th>sensor_27</th>\n      <th>sensor_28</th>\n      <th>sensor_29</th>\n      <th>sensor_30</th>\n      <th>sensor_31</th>\n      <th>sensor_32</th>\n      <th>sensor_33</th>\n      <th>sensor_34</th>\n      <th>sensor_35</th>\n      <th>sensor_36</th>\n      <th>sensor_37</th>\n      <th>sensor_38</th>\n      <th>sensor_39</th>\n      <th>sensor_40</th>\n      <th>sensor_41</th>\n      <th>sensor_42</th>\n      <th>sensor_43</th>\n      <th>sensor_44</th>\n      <th>sensor_45</th>\n      <th>sensor_46</th>\n      <th>sensor_47</th>\n      <th>sensor_48</th>\n      <th>sensor_49</th>\n      <th>sensor_50</th>\n      <th>sensor_51</th>\n      <th>machine_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2018-04-01 00:00:00</td>\n      <td>0.231450</td>\n      <td>-0.151675</td>\n      <td>0.639386</td>\n      <td>1.057675</td>\n      <td>0.303443</td>\n      <td>0.177097</td>\n      <td>-0.042091</td>\n      <td>0.132586</td>\n      <td>0.181964</td>\n      <td>0.122858</td>\n      <td>-0.350860</td>\n      <td>0.429379</td>\n      <td>0.195797</td>\n      <td>-0.782084</td>\n      <td>0.377336</td>\n      <td>0.360177</td>\n      <td>0.350008</td>\n      <td>0.341471</td>\n      <td>0.374086</td>\n      <td>0.374433</td>\n      <td>0.369586</td>\n      <td>0.253051</td>\n      <td>0.182753</td>\n      <td>0.391893</td>\n      <td>0.419161</td>\n      <td>0.249984</td>\n      <td>-0.426748</td>\n      <td>-0.212408</td>\n      <td>0.481773</td>\n      <td>-0.103021</td>\n      <td>-0.636646</td>\n      <td>-0.475290</td>\n      <td>-0.349610</td>\n      <td>-0.713278</td>\n      <td>-0.601169</td>\n      <td>-1.375272</td>\n      <td>0.785474</td>\n      <td>-0.881557</td>\n      <td>-0.326658</td>\n      <td>0.080880</td>\n      <td>-0.553995</td>\n      <td>-0.358970</td>\n      <td>-0.176799</td>\n      <td>-0.260520</td>\n      <td>1.759633</td>\n      <td>0.185888</td>\n      <td>-0.588642</td>\n      <td>0.086297</td>\n      <td>0.553138</td>\n      <td>1.140144</td>\n      <td>-0.012402</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2018-04-01 00:01:00</td>\n      <td>0.231450</td>\n      <td>-0.151675</td>\n      <td>0.639386</td>\n      <td>1.057675</td>\n      <td>0.303443</td>\n      <td>0.177097</td>\n      <td>-0.042091</td>\n      <td>0.132586</td>\n      <td>0.181964</td>\n      <td>0.122858</td>\n      <td>-0.350860</td>\n      <td>0.429379</td>\n      <td>0.195797</td>\n      <td>-0.782084</td>\n      <td>0.377336</td>\n      <td>0.360177</td>\n      <td>0.350008</td>\n      <td>0.341471</td>\n      <td>0.374086</td>\n      <td>0.374433</td>\n      <td>0.369586</td>\n      <td>0.253051</td>\n      <td>0.182753</td>\n      <td>0.391893</td>\n      <td>0.419161</td>\n      <td>0.249984</td>\n      <td>-0.426748</td>\n      <td>-0.212408</td>\n      <td>0.481773</td>\n      <td>-0.103021</td>\n      <td>-0.636646</td>\n      <td>-0.475290</td>\n      <td>-0.349610</td>\n      <td>-0.713278</td>\n      <td>-0.601169</td>\n      <td>-1.375272</td>\n      <td>0.785474</td>\n      <td>-0.881557</td>\n      <td>-0.326658</td>\n      <td>0.080880</td>\n      <td>-0.553995</td>\n      <td>-0.358970</td>\n      <td>-0.176799</td>\n      <td>-0.260520</td>\n      <td>1.759633</td>\n      <td>0.185888</td>\n      <td>-0.588642</td>\n      <td>0.086297</td>\n      <td>0.553138</td>\n      <td>1.140144</td>\n      <td>-0.012402</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2018-04-01 00:02:00</td>\n      <td>0.180129</td>\n      <td>-0.072613</td>\n      <td>0.639386</td>\n      <td>1.093565</td>\n      <td>0.334786</td>\n      <td>0.008647</td>\n      <td>-0.082656</td>\n      <td>0.089329</td>\n      <td>0.207112</td>\n      <td>0.101892</td>\n      <td>-0.297906</td>\n      <td>0.479396</td>\n      <td>0.291884</td>\n      <td>-0.778154</td>\n      <td>0.388584</td>\n      <td>0.367330</td>\n      <td>0.298189</td>\n      <td>0.256303</td>\n      <td>0.378220</td>\n      <td>0.383805</td>\n      <td>0.371454</td>\n      <td>0.269031</td>\n      <td>0.206031</td>\n      <td>0.410866</td>\n      <td>0.415031</td>\n      <td>0.257399</td>\n      <td>-0.278345</td>\n      <td>-0.233554</td>\n      <td>0.617700</td>\n      <td>0.240159</td>\n      <td>-0.498876</td>\n      <td>-0.420292</td>\n      <td>-0.299461</td>\n      <td>-0.735406</td>\n      <td>-0.592058</td>\n      <td>-1.354869</td>\n      <td>0.880710</td>\n      <td>-0.782724</td>\n      <td>-0.343338</td>\n      <td>0.032135</td>\n      <td>-0.619939</td>\n      <td>-0.358970</td>\n      <td>-0.200379</td>\n      <td>-0.285516</td>\n      <td>1.737092</td>\n      <td>0.204388</td>\n      <td>-0.588641</td>\n      <td>0.061668</td>\n      <td>0.522906</td>\n      <td>1.107156</td>\n      <td>0.009499</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2018-04-01 00:03:00</td>\n      <td>0.219228</td>\n      <td>-0.151675</td>\n      <td>0.627550</td>\n      <td>1.093564</td>\n      <td>0.260045</td>\n      <td>0.207693</td>\n      <td>-0.086035</td>\n      <td>0.185835</td>\n      <td>0.246628</td>\n      <td>0.136839</td>\n      <td>-0.239029</td>\n      <td>0.516072</td>\n      <td>0.250679</td>\n      <td>-0.796852</td>\n      <td>0.387713</td>\n      <td>0.368268</td>\n      <td>0.307864</td>\n      <td>0.268655</td>\n      <td>0.377156</td>\n      <td>0.375594</td>\n      <td>0.364696</td>\n      <td>0.254024</td>\n      <td>0.188959</td>\n      <td>0.379460</td>\n      <td>0.408100</td>\n      <td>0.248715</td>\n      <td>-0.156837</td>\n      <td>-0.230565</td>\n      <td>0.505947</td>\n      <td>0.365597</td>\n      <td>-0.383149</td>\n      <td>-0.464001</td>\n      <td>-0.266386</td>\n      <td>-0.774822</td>\n      <td>-0.586675</td>\n      <td>-1.381826</td>\n      <td>1.070467</td>\n      <td>-0.733308</td>\n      <td>-0.326658</td>\n      <td>0.153997</td>\n      <td>-0.619939</td>\n      <td>-0.384354</td>\n      <td>-0.271121</td>\n      <td>-0.310513</td>\n      <td>1.692010</td>\n      <td>0.204388</td>\n      <td>-0.588642</td>\n      <td>0.061668</td>\n      <td>0.507790</td>\n      <td>1.090664</td>\n      <td>0.004024</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>2018-04-01 00:04:00</td>\n      <td>0.182573</td>\n      <td>-0.138499</td>\n      <td>0.639386</td>\n      <td>1.093564</td>\n      <td>0.317909</td>\n      <td>0.184568</td>\n      <td>-0.069133</td>\n      <td>0.169195</td>\n      <td>0.246628</td>\n      <td>0.136839</td>\n      <td>-0.163810</td>\n      <td>0.547239</td>\n      <td>0.278346</td>\n      <td>-0.781725</td>\n      <td>0.380144</td>\n      <td>0.357103</td>\n      <td>0.364660</td>\n      <td>0.393052</td>\n      <td>0.363108</td>\n      <td>0.389697</td>\n      <td>0.381000</td>\n      <td>0.250758</td>\n      <td>0.195207</td>\n      <td>0.389200</td>\n      <td>0.400543</td>\n      <td>0.245311</td>\n      <td>-0.545828</td>\n      <td>-0.212289</td>\n      <td>0.569265</td>\n      <td>0.086319</td>\n      <td>-0.342736</td>\n      <td>-0.390851</td>\n      <td>-0.348254</td>\n      <td>-0.794612</td>\n      <td>-0.614859</td>\n      <td>-1.379379</td>\n      <td>1.088104</td>\n      <td>-0.659184</td>\n      <td>-0.326658</td>\n      <td>0.373349</td>\n      <td>-0.553995</td>\n      <td>-0.384354</td>\n      <td>-0.223959</td>\n      <td>-0.335509</td>\n      <td>1.714550</td>\n      <td>0.241389</td>\n      <td>-0.533219</td>\n      <td>0.089816</td>\n      <td>0.492674</td>\n      <td>1.123650</td>\n      <td>-0.012402</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "   Id            timestamp  sensor_00  sensor_01  sensor_02  sensor_03  \\\n0   0  2018-04-01 00:00:00   0.231450  -0.151675   0.639386   1.057675   \n1   1  2018-04-01 00:01:00   0.231450  -0.151675   0.639386   1.057675   \n2   2  2018-04-01 00:02:00   0.180129  -0.072613   0.639386   1.093565   \n3   3  2018-04-01 00:03:00   0.219228  -0.151675   0.627550   1.093564   \n4   4  2018-04-01 00:04:00   0.182573  -0.138499   0.639386   1.093564   \n\n   sensor_04  sensor_05  sensor_06  sensor_07  sensor_08  sensor_09  \\\n0   0.303443   0.177097  -0.042091   0.132586   0.181964   0.122858   \n1   0.303443   0.177097  -0.042091   0.132586   0.181964   0.122858   \n2   0.334786   0.008647  -0.082656   0.089329   0.207112   0.101892   \n3   0.260045   0.207693  -0.086035   0.185835   0.246628   0.136839   \n4   0.317909   0.184568  -0.069133   0.169195   0.246628   0.136839   \n\n   sensor_10  sensor_11  sensor_12  sensor_13  sensor_14  sensor_16  \\\n0  -0.350860   0.429379   0.195797  -0.782084   0.377336   0.360177   \n1  -0.350860   0.429379   0.195797  -0.782084   0.377336   0.360177   \n2  -0.297906   0.479396   0.291884  -0.778154   0.388584   0.367330   \n3  -0.239029   0.516072   0.250679  -0.796852   0.387713   0.368268   \n4  -0.163810   0.547239   0.278346  -0.781725   0.380144   0.357103   \n\n   sensor_17  sensor_18  sensor_19  sensor_20  sensor_21  sensor_22  \\\n0   0.350008   0.341471   0.374086   0.374433   0.369586   0.253051   \n1   0.350008   0.341471   0.374086   0.374433   0.369586   0.253051   \n2   0.298189   0.256303   0.378220   0.383805   0.371454   0.269031   \n3   0.307864   0.268655   0.377156   0.375594   0.364696   0.254024   \n4   0.364660   0.393052   0.363108   0.389697   0.381000   0.250758   \n\n   sensor_23  sensor_24  sensor_25  sensor_26  sensor_27  sensor_28  \\\n0   0.182753   0.391893   0.419161   0.249984  -0.426748  -0.212408   \n1   0.182753   0.391893   0.419161   0.249984  -0.426748  -0.212408   \n2   0.206031   0.410866   0.415031   0.257399  -0.278345  -0.233554   \n3   0.188959   0.379460   0.408100   0.248715  -0.156837  -0.230565   \n4   0.195207   0.389200   0.400543   0.245311  -0.545828  -0.212289   \n\n   sensor_29  sensor_30  sensor_31  sensor_32  sensor_33  sensor_34  \\\n0   0.481773  -0.103021  -0.636646  -0.475290  -0.349610  -0.713278   \n1   0.481773  -0.103021  -0.636646  -0.475290  -0.349610  -0.713278   \n2   0.617700   0.240159  -0.498876  -0.420292  -0.299461  -0.735406   \n3   0.505947   0.365597  -0.383149  -0.464001  -0.266386  -0.774822   \n4   0.569265   0.086319  -0.342736  -0.390851  -0.348254  -0.794612   \n\n   sensor_35  sensor_36  sensor_37  sensor_38  sensor_39  sensor_40  \\\n0  -0.601169  -1.375272   0.785474  -0.881557  -0.326658   0.080880   \n1  -0.601169  -1.375272   0.785474  -0.881557  -0.326658   0.080880   \n2  -0.592058  -1.354869   0.880710  -0.782724  -0.343338   0.032135   \n3  -0.586675  -1.381826   1.070467  -0.733308  -0.326658   0.153997   \n4  -0.614859  -1.379379   1.088104  -0.659184  -0.326658   0.373349   \n\n   sensor_41  sensor_42  sensor_43  sensor_44  sensor_45  sensor_46  \\\n0  -0.553995  -0.358970  -0.176799  -0.260520   1.759633   0.185888   \n1  -0.553995  -0.358970  -0.176799  -0.260520   1.759633   0.185888   \n2  -0.619939  -0.358970  -0.200379  -0.285516   1.737092   0.204388   \n3  -0.619939  -0.384354  -0.271121  -0.310513   1.692010   0.204388   \n4  -0.553995  -0.384354  -0.223959  -0.335509   1.714550   0.241389   \n\n   sensor_47  sensor_48  sensor_49  sensor_50  sensor_51  machine_status  \n0  -0.588642   0.086297   0.553138   1.140144  -0.012402               1  \n1  -0.588642   0.086297   0.553138   1.140144  -0.012402               1  \n2  -0.588641   0.061668   0.522906   1.107156   0.009499               1  \n3  -0.588642   0.061668   0.507790   1.090664   0.004024               1  \n4  -0.533219   0.089816   0.492674   1.123650  -0.012402               1  "
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>machine_status</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.010524</td>\n      <td>0.776836</td>\n      <td>-0.522604</td>\n      <td>-0.782975</td>\n      <td>-1.943597</td>\n      <td>1.535913</td>\n      <td>-1.132301</td>\n      <td>-0.175648</td>\n      <td>-1.079528</td>\n      <td>-0.922840</td>\n      <td>-0.261418</td>\n      <td>-0.087582</td>\n      <td>0.276406</td>\n      <td>-0.182030</td>\n      <td>-0.130302</td>\n      <td>-0.102301</td>\n      <td>-0.212444</td>\n      <td>-0.318682</td>\n      <td>-0.307934</td>\n      <td>-0.092294</td>\n      <td>1.258369</td>\n      <td>0.720922</td>\n      <td>0.052926</td>\n      <td>0.027548</td>\n      <td>-0.231165</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.010524</td>\n      <td>0.776836</td>\n      <td>-0.522604</td>\n      <td>-0.782975</td>\n      <td>-1.943597</td>\n      <td>1.535913</td>\n      <td>-1.132301</td>\n      <td>-0.175648</td>\n      <td>-1.079528</td>\n      <td>-0.922840</td>\n      <td>-0.261418</td>\n      <td>-0.087582</td>\n      <td>0.276406</td>\n      <td>-0.182030</td>\n      <td>-0.130302</td>\n      <td>-0.102301</td>\n      <td>-0.212444</td>\n      <td>-0.318682</td>\n      <td>-0.307934</td>\n      <td>-0.092294</td>\n      <td>1.258369</td>\n      <td>0.720922</td>\n      <td>0.052926</td>\n      <td>0.027548</td>\n      <td>-0.231165</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.151425</td>\n      <td>0.782444</td>\n      <td>-0.493743</td>\n      <td>-0.843039</td>\n      <td>-2.105161</td>\n      <td>1.502969</td>\n      <td>-1.128054</td>\n      <td>-0.031836</td>\n      <td>-0.955613</td>\n      <td>-0.787217</td>\n      <td>-0.285881</td>\n      <td>-0.095448</td>\n      <td>0.120880</td>\n      <td>-0.162924</td>\n      <td>-0.079332</td>\n      <td>-0.094471</td>\n      <td>-0.234212</td>\n      <td>-0.226885</td>\n      <td>-0.230350</td>\n      <td>-0.157058</td>\n      <td>1.151771</td>\n      <td>0.812048</td>\n      <td>-0.000399</td>\n      <td>0.046491</td>\n      <td>-0.308556</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.151886</td>\n      <td>0.816479</td>\n      <td>-0.541572</td>\n      <td>-0.971684</td>\n      <td>-2.012970</td>\n      <td>1.586361</td>\n      <td>-1.169678</td>\n      <td>-0.009723</td>\n      <td>-0.820260</td>\n      <td>-0.656993</td>\n      <td>-0.279351</td>\n      <td>-0.077121</td>\n      <td>0.195787</td>\n      <td>-0.206480</td>\n      <td>-0.044681</td>\n      <td>0.007526</td>\n      <td>-0.370786</td>\n      <td>-0.347226</td>\n      <td>-0.283856</td>\n      <td>-0.171418</td>\n      <td>1.182390</td>\n      <td>0.814355</td>\n      <td>-0.080590</td>\n      <td>0.053642</td>\n      <td>-0.393504</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.106250</td>\n      <td>0.929110</td>\n      <td>-0.407707</td>\n      <td>-1.025532</td>\n      <td>-1.989539</td>\n      <td>1.511101</td>\n      <td>-1.171104</td>\n      <td>-0.146129</td>\n      <td>-1.093221</td>\n      <td>-0.809584</td>\n      <td>-0.145487</td>\n      <td>-0.011419</td>\n      <td>0.105777</td>\n      <td>-0.163773</td>\n      <td>-0.049583</td>\n      <td>0.131315</td>\n      <td>-0.432011</td>\n      <td>-0.406039</td>\n      <td>-0.170682</td>\n      <td>-0.070666</td>\n      <td>1.158419</td>\n      <td>0.747454</td>\n      <td>-0.013814</td>\n      <td>0.041475</td>\n      <td>-0.431086</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "          0         1         2         3         4         5         6  \\\n0 -0.010524  0.776836 -0.522604 -0.782975 -1.943597  1.535913 -1.132301   \n1 -0.010524  0.776836 -0.522604 -0.782975 -1.943597  1.535913 -1.132301   \n2 -0.151425  0.782444 -0.493743 -0.843039 -2.105161  1.502969 -1.128054   \n3 -0.151886  0.816479 -0.541572 -0.971684 -2.012970  1.586361 -1.169678   \n4 -0.106250  0.929110 -0.407707 -1.025532 -1.989539  1.511101 -1.171104   \n\n          7         8         9        10        11        12        13  \\\n0 -0.175648 -1.079528 -0.922840 -0.261418 -0.087582  0.276406 -0.182030   \n1 -0.175648 -1.079528 -0.922840 -0.261418 -0.087582  0.276406 -0.182030   \n2 -0.031836 -0.955613 -0.787217 -0.285881 -0.095448  0.120880 -0.162924   \n3 -0.009723 -0.820260 -0.656993 -0.279351 -0.077121  0.195787 -0.206480   \n4 -0.146129 -1.093221 -0.809584 -0.145487 -0.011419  0.105777 -0.163773   \n\n         14        15        16        17        18        19        20  \\\n0 -0.130302 -0.102301 -0.212444 -0.318682 -0.307934 -0.092294  1.258369   \n1 -0.130302 -0.102301 -0.212444 -0.318682 -0.307934 -0.092294  1.258369   \n2 -0.079332 -0.094471 -0.234212 -0.226885 -0.230350 -0.157058  1.151771   \n3 -0.044681  0.007526 -0.370786 -0.347226 -0.283856 -0.171418  1.182390   \n4 -0.049583  0.131315 -0.432011 -0.406039 -0.170682 -0.070666  1.158419   \n\n         21        22        23        24  machine_status  \n0  0.720922  0.052926  0.027548 -0.231165               1  \n1  0.720922  0.052926  0.027548 -0.231165               1  \n2  0.812048 -0.000399  0.046491 -0.308556               1  \n3  0.814355 -0.080590  0.053642 -0.393504               1  \n4  0.747454 -0.013814  0.041475 -0.431086               1  "
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "#This is were all of the imports used in the final model are initiated\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import matthews_corrcoef"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Split the Data</h2>\n<p>In order to prevent overfitting the data is split into train and test sets. </p>"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": "#The sensor data is split from the rest of the DataFrame as the features in the SVM Model\nkey_data = data.loc[:,'sensor_00': 'machine_status']\nX = key_data.loc[:,'sensor_00': 'sensor_51']\ny = key_data.machine_status\n\nX_pca = data_pca.loc[:,'0':'24']\ny_pca = data_pca.machine_status\n"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": "#Train_test_split used to check the accuracy of the data and to check for any overfitting.\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\nX_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y_pca, test_size = 0.2)"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "#The hypertuning parameters are laid out here\nkern = ['linear', 'poly', 'rbf', 'sigmoid']\ngamma = ['scale', 'auto']\n\nparam = {'kernel': kern, 'gamma': gamma}"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>First Hyperparameter Tuning</h2>\n<p>\n    The first tuning is trained using the 51 sensors from the water pump. The best parameters are printed out and the final scores are calculated.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 40.2min finished\n"
                },
                {
                    "data": {
                        "text/plain": "GridSearchCV(estimator=SVC(),\n             param_grid={'gamma': ['scale', 'auto'],\n                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n             verbose=1)"
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "#The GridSearch for hyperparameters is done here. The SVC instance is instantiated put into the GridSearchCV from sklearn and the fit done\nsvc = SVC()\nclf = GridSearchCV(svc, param, verbose = 1)\nclf.fit(X_train, y_train)"
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'gamma': 'scale', 'kernel': 'poly'}"
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "#Best hypertuning parameters\nclf.best_params_"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": "#After the GridSearch is run the best model is predicted using the test data\ny_pred = clf.predict(X_test)"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "#The best model is tested using f1_score\nf1 = f1_score(y_test, y_pred)\nphi = matthews_corrcoef(y_test, y_pred)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Second Hyperparameter Tuning</h2>\n<p>\n    The second hyperparameter tuning is done on the PCA sensor data from the feature creation notebook. The best parameters are printed out and the final scores are calculated.\n</p>"
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 40.3min finished\n"
                },
                {
                    "data": {
                        "text/plain": "GridSearchCV(estimator=SVC(),\n             param_grid={'gamma': ['scale', 'auto'],\n                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n             verbose=1)"
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "#The GridSearch for hyperparameters is done here. The SVC instance is instantiated put into the GridSearchCV from sklearn and the fit done\nsvc2 = SVC()\nclf2 = GridSearchCV(svc2, param, verbose = 1)\nclf2.fit(X_train_pca, y_train_pca)"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'gamma': 'auto', 'kernel': 'poly'}"
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "#Best hypertuning parameters\nclf2.best_params_"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "#After the GridSearch is run the best model is predicted using the test data\ny_pred_pca = clf2.predict(X_test_pca)"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": "#The best model is tested using f1_score and matthews correlation coefficient\nf1_pca = f1_score(y_test_pca, y_pred_pca)\nphi_pca = matthews_corrcoef(y_test_pca, y_pred_pca)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Final Score for Each Feature Creation Iteration</h2>"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Original Iteration\nF1 Score: 0.9999027639351434\nMatthews Corr Coeficient: 0.9985364444899135\nPCA Iteration\nF1 Score: 0.9999269326318866\nMatthews Corr Coeficient: 0.9989295017009503\n"
                }
            ],
            "source": "#Printouts of the score for the two types with standard data\nprint('Original Iteration')\nprint('F1 Score: {}'.format(f1))\nprint('Matthews Corr Coeficient: {}'.format(phi))\n\n#Printouts of the score for the two types with PCA data\nprint('PCA Iteration')\nprint('F1 Score: {}'.format(f1_pca))\nprint('Matthews Corr Coeficient: {}'.format(phi_pca))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Conclusion</h2>\n<p>\n    The goal of this notebook was to test if a non deep learning model could accurately predict whether the pump is running normally or is in a broken or recovering state. The F1-score and the Matthews Correlation Coefficient shows that the goal was met. With both scores being above 0.99, the model seems to predict the pump accurately. The reason both scores are used in this case is that the F1-score is a well known accuracy measurement and the Matthews Correlation Coefficient also takes the true negatives into account. Taking true negatives into account is very important in this case as we want to be very accurate in predicting the broken state. The second iteration using PCA did not provide any benefit in this case. With further PCA reduction the model may have been able to train faster and be more accurate, but the current PCA was slower and about the same accuracy. To conclude, the model was accurate and did not take long to train, therefore our goal was met.\n</p>"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.7",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}